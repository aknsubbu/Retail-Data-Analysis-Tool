{"id":"692a481f-bc9e-4ade-b11f-0a4304c0a6e9","data":{"nodes":[{"id":"MongoDBAtlasVector-QL9hJ","type":"genericNode","position":{"x":1454.3818331975324,"y":-211.89296559422277},"data":{"type":"MongoDBAtlasVector","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langchain_community.vectorstores.mongodb_atlas import MongoDBAtlasVectorSearch\nfrom langflow.field_typing import Embeddings\nfrom langflow.interface.custom.custom_component import CustomComponent\nfrom langflow.schema.schema import Record\n\n\nclass MongoDBAtlasComponent(CustomComponent):\n    display_name = \"MongoDB Atlas\"\n    description = \"Construct a `MongoDB Atlas Vector Search` vector store from raw documents.\"\n    icon = \"MongoDB\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"collection_name\": {\"display_name\": \"Collection Name\"},\n            \"db_name\": {\"display_name\": \"Database Name\"},\n            \"index_name\": {\"display_name\": \"Index Name\"},\n            \"mongodb_atlas_cluster_uri\": {\"display_name\": \"MongoDB Atlas Cluster URI\"},\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        inputs: Optional[List[Record]] = None,\n        collection_name: str = \"\",\n        db_name: str = \"\",\n        index_name: str = \"\",\n        mongodb_atlas_cluster_uri: str = \"\",\n    ) -> MongoDBAtlasVectorSearch:\n        try:\n            from pymongo import MongoClient\n        except ImportError:\n            raise ImportError(\"Please install pymongo to use MongoDB Atlas Vector Store\")\n        try:\n            mongo_client: MongoClient = MongoClient(mongodb_atlas_cluster_uri)\n            collection = mongo_client[db_name][collection_name]\n        except Exception as e:\n            raise ValueError(f\"Failed to connect to MongoDB Atlas: {e}\")\n        documents = []\n        for _input in inputs or []:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        if documents:\n            vector_store = MongoDBAtlasVectorSearch.from_documents(\n                documents=documents,\n                embedding=embedding,\n                collection=collection,\n                db_name=db_name,\n                index_name=index_name,\n                mongodb_atlas_cluster_uri=mongodb_atlas_cluster_uri,\n            )\n        else:\n            vector_store = MongoDBAtlasVectorSearch(\n                embedding=embedding,\n                collection=collection,\n                index_name=index_name,\n            )\n        return vector_store\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"db_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"db_name","display_name":"Database Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"index_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"index_name","display_name":"Index Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"mongodb_atlas_cluster_uri":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"mongodb_atlas_cluster_uri","display_name":"MongoDB Atlas Cluster URI","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Construct a `MongoDB Atlas Vector Search` vector store from raw documents.","icon":"MongoDB","base_classes":["MongoDBAtlasVectorSearch","VectorStore"],"display_name":"MongoDB Atlas","documentation":"","custom_fields":{"embedding":null,"inputs":null,"collection_name":null,"db_name":null,"index_name":null,"mongodb_atlas_cluster_uri":null},"output_types":["MongoDBAtlasVectorSearch"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"MongoDBAtlasVector-QL9hJ"},"selected":false,"width":384,"height":687,"positionAbsolute":{"x":1454.3818331975324,"y":-211.89296559422277},"dragging":false},{"id":"MongoDBAtlasVectorSearch-PY4MJ","type":"genericNode","position":{"x":1189.0359299529828,"y":579.6280886769449},"data":{"type":"MongoDBAtlasVectorSearch","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langflow.components.vectorstores.base.model import LCVectorStoreComponent\nfrom langflow.components.vectorstores.MongoDBAtlasVector import MongoDBAtlasComponent\nfrom langflow.field_typing import Embeddings, NestedDict, Text\nfrom langflow.schema import Record\n\n\nclass MongoDBAtlasSearchComponent(LCVectorStoreComponent):\n    display_name = \"MongoDB Atlas Search\"\n    description = \"Search a MongoDB Atlas Vector Store for similar documents.\"\n\n    def build_config(self):\n        return {\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"collection_name\": {\"display_name\": \"Collection Name\"},\n            \"db_name\": {\"display_name\": \"Database Name\"},\n            \"index_name\": {\"display_name\": \"Index Name\"},\n            \"mongodb_atlas_cluster_uri\": {\"display_name\": \"MongoDB Atlas Cluster URI\"},\n            \"search_kwargs\": {\"display_name\": \"Search Kwargs\", \"advanced\": True},\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(  # type: ignore[override]\n        self,\n        input_value: Text,\n        search_type: str,\n        embedding: Embeddings,\n        number_of_results: int = 4,\n        collection_name: str = \"\",\n        db_name: str = \"\",\n        index_name: str = \"\",\n        mongodb_atlas_cluster_uri: str = \"\",\n        search_kwargs: Optional[NestedDict] = None,\n    ) -> List[Record]:\n        search_kwargs = search_kwargs or {}\n        vector_store = MongoDBAtlasComponent().build(\n            mongodb_atlas_cluster_uri=mongodb_atlas_cluster_uri,\n            collection_name=collection_name,\n            db_name=db_name,\n            embedding=embedding,\n            index_name=index_name,\n        )\n        if not vector_store:\n            raise ValueError(\"Failed to create MongoDB Atlas Vector Store\")\n        return self.search_with_vector_store(\n            vector_store=vector_store, input_value=input_value, search_type=search_type, k=number_of_results\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"db_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"db_name","display_name":"Database Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"index_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"index_name","display_name":"Index Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"mongodb_atlas_cluster_uri":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"mongodb_atlas_cluster_uri","display_name":"MongoDB Atlas Cluster URI","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"number_of_results":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":4,"fileTypes":[],"file_path":"","password":false,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","load_from_db":false,"title_case":false},"search_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"search_kwargs","display_name":"Search Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"search_type":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"options":["Similarity","MMR"],"name":"search_type","display_name":"Search Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Search a MongoDB Atlas Vector Store for similar documents.","base_classes":["Record"],"display_name":"MongoDB Atlas Search","documentation":"","custom_fields":{"input_value":null,"search_type":null,"embedding":null,"number_of_results":null,"collection_name":null,"db_name":null,"index_name":null,"mongodb_atlas_cluster_uri":null,"search_kwargs":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"MongoDBAtlasVectorSearch-PY4MJ"},"selected":true,"width":384,"height":827,"positionAbsolute":{"x":1189.0359299529828,"y":579.6280886769449},"dragging":false},{"id":"OllamaEmbeddings-G77ye","type":"genericNode","position":{"x":394.14842182505015,"y":692.775135215705},"data":{"type":"OllamaEmbeddings","node":{"template":{"base_url":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"http://localhost:11434","fileTypes":[],"file_path":"","password":false,"name":"base_url","display_name":"Ollama Base URL","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain.embeddings.base import Embeddings\nfrom langchain_community.embeddings import OllamaEmbeddings\n\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass OllamaEmbeddingsComponent(CustomComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Ollama Model\",\n            },\n            \"base_url\": {\"display_name\": \"Ollama Base URL\"},\n            \"temperature\": {\"display_name\": \"Model Temperature\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str = \"llama2\",\n        base_url: str = \"http://localhost:11434\",\n        temperature: Optional[float] = None,\n    ) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=model, base_url=base_url, temperature=temperature)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"model":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"llama2","fileTypes":[],"file_path":"","password":false,"name":"model","display_name":"Ollama Model","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Model Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate embeddings using Ollama models.","base_classes":["Embeddings"],"display_name":"Ollama Embeddings","documentation":"https://python.langchain.com/docs/integrations/text_embedding/ollama","custom_fields":{"model":null,"base_url":null,"temperature":null},"output_types":["Embeddings"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"OllamaEmbeddings-G77ye"},"selected":false,"width":384,"height":469,"positionAbsolute":{"x":394.14842182505015,"y":692.775135215705},"dragging":false},{"id":"Prompt-qz9Jn","type":"genericNode","position":{"x":-527.9655650728906,"y":53.115557321082576},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.prompts import PromptTemplate\n\nfrom langflow.field_typing import Prompt, TemplateField, Text\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"You are a Retail Customer Data Analysis Model...\n\nHere is the collection name: {collection_name}\n\nHere is the name of the data: {data_field_desc}\n\nFind all possible patterns in the data and provide suggestion to improve customer interaction and spending ","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","collection_name":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"collection_name","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"data_field_desc":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"data_field_desc","display_name":"data_field_desc","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["object","str","Text"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["collection_name","data_field_desc"]},"output_types":["Text"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-qz9Jn","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":477,"positionAbsolute":{"x":-527.9655650728906,"y":53.115557321082576},"dragging":false},{"id":"TextInput-axe6h","type":"genericNode","position":{"x":-1027.8601536441752,"y":109.20129164859259},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Value","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Collection Name","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-axe6h"},"selected":false,"width":384,"height":289,"positionAbsolute":{"x":-1027.8601536441752,"y":109.20129164859259},"dragging":false},{"id":"TextInput-9uD8V","type":"genericNode","position":{"x":-1016.5679075670043,"y":430.55474649531953},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Value","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Data Field Desc","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-9uD8V"},"selected":false,"width":384,"height":289,"positionAbsolute":{"x":-1016.5679075670043,"y":430.55474649531953},"dragging":false},{"id":"LanguageRecursiveTextSplitter-xQXxD","type":"genericNode","position":{"x":1752.9836892991577,"y":615.0579888924608},"data":{"type":"LanguageRecursiveTextSplitter","node":{"template":{"inputs":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chunk_overlap":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":200,"fileTypes":[],"file_path":"","password":false,"name":"chunk_overlap","display_name":"Chunk Overlap","advanced":false,"dynamic":false,"info":"The amount of overlap between chunks.","load_from_db":false,"title_case":false},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":false,"dynamic":false,"info":"The maximum length of each chunk.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langchain.text_splitter import Language\n\nfrom langflow.interface.custom.custom_component import CustomComponent\nfrom langflow.schema.schema import Record\n\n\nclass LanguageRecursiveTextSplitterComponent(CustomComponent):\n    display_name: str = \"Language Recursive Text Splitter\"\n    description: str = \"Split text into chunks of a specified length based on language.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter\"\n\n    def build_config(self):\n        options = [x.value for x in Language]\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"separator_type\": {\n                \"display_name\": \"Separator Type\",\n                \"info\": \"The type of separator to use.\",\n                \"field_type\": \"str\",\n                \"options\": options,\n                \"value\": \"Python\",\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": \"The characters to split on.\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        inputs: List[Record],\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n        separator_type: str = \"Python\",\n    ) -> list[Record]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n        from langchain.text_splitter import RecursiveCharacterTextSplitter\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n\n        splitter = RecursiveCharacterTextSplitter.from_language(\n            language=Language(separator_type),\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = splitter.split_documents(documents)\n        records = self.to_records(docs)\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"separator_type":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"python","fileTypes":[],"file_path":"","password":false,"options":["cpp","go","java","kotlin","js","ts","php","proto","python","rst","ruby","rust","scala","swift","markdown","latex","html","sol","csharp","cobol","c","lua","perl"],"name":"separator_type","display_name":"Separator Type","advanced":false,"dynamic":false,"info":"The type of separator to use.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Split text into chunks of a specified length based on language.","base_classes":["Record"],"display_name":"Language Recursive Text Splitter","documentation":"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter","custom_fields":{"inputs":null,"chunk_size":null,"chunk_overlap":null,"separator_type":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"LanguageRecursiveTextSplitter-xQXxD"},"selected":false,"width":384,"height":529,"positionAbsolute":{"x":1752.9836892991577,"y":615.0579888924608},"dragging":false},{"id":"OllamaModel-ThRiU","type":"genericNode","position":{"x":-73.7630007481905,"y":-65.49065680954584},"data":{"type":"OllamaModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata":{"type":"Dict[str, Any]","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata","display_name":"Metadata","advanced":true,"dynamic":false,"info":"Metadata to add to the run trace.","load_from_db":false,"title_case":false},"stop":{"type":"list","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"stop","display_name":"Stop Tokens","advanced":true,"dynamic":false,"info":"List of tokens to signal the model to stop generating text.","load_from_db":false,"title_case":false},"tags":{"type":"list","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tags","display_name":"Tags","advanced":true,"dynamic":false,"info":"Tags to add to the run trace.","load_from_db":false,"title_case":false},"base_url":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"base_url","display_name":"Base URL","advanced":true,"dynamic":false,"info":"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.","load_from_db":false,"title_case":false,"input_types":["Text"]},"cache":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"cache","display_name":"Cache","advanced":true,"dynamic":false,"info":"Enable or disable caching.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Any, Dict, List, Optional\n\n# from langchain_community.chat_models import ChatOllama\nfrom langchain_community.chat_models import ChatOllama\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\n\n# from langchain.chat_models import ChatOllama\nfrom langflow.field_typing import Text\n\n# whe When a callback component is added to Langflow, the comment must be uncommented.\n# from langchain.callbacks.manager import CallbackManager\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n\n    field_order = [\n        \"base_url\",\n        \"model\",\n        \"temperature\",\n        \"cache\",\n        \"callback_manager\",\n        \"callbacks\",\n        \"format\",\n        \"metadata\",\n        \"mirostat\",\n        \"mirostat_eta\",\n        \"mirostat_tau\",\n        \"num_ctx\",\n        \"num_gpu\",\n        \"num_thread\",\n        \"repeat_last_n\",\n        \"repeat_penalty\",\n        \"tfs_z\",\n        \"timeout\",\n        \"top_k\",\n        \"top_p\",\n        \"verbose\",\n        \"tags\",\n        \"stop\",\n        \"system\",\n        \"template\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n                \"advanced\": True,\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"cache\": {\n                \"display_name\": \"Cache\",\n                \"field_type\": \"bool\",\n                \"info\": \"Enable or disable caching.\",\n                \"advanced\": True,\n                \"value\": False,\n            },\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\n            # \"callback_manager\": {\n            #     \"display_name\": \"Callback Manager\",\n            #     \"info\": \"Optional callback manager for additional functionality.\",\n            #     \"advanced\": True,\n            # },\n            # \"callbacks\": {\n            #     \"display_name\": \"Callbacks\",\n            #     \"info\": \"Callbacks to execute during model runtime.\",\n            #     \"advanced\": True,\n            # },\n            ########################################################################################\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"field_type\": \"str\",\n                \"info\": \"Specify the format of the output (e.g., json).\",\n                \"advanced\": True,\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        input_value: Text,\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\n        # callback_manager: Optional[CallbackManager] = None,\n        # callbacks: Optional[List[Callbacks]] = None,\n        #######################################################################################\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        cache: Optional[bool] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"cache\": cache,\n            \"model\": model,\n            \"mirostat\": mirostat_value,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\n            # \"callback_manager\": callback_manager,\n            # \"callbacks\": callbacks,\n            #####################################################################################\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"format":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"format","display_name":"Format","advanced":true,"dynamic":false,"info":"Specify the format of the output (e.g., json).","load_from_db":false,"title_case":false,"input_types":["Text"]},"mirostat":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Disabled","fileTypes":[],"file_path":"","password":false,"options":["Disabled","Mirostat","Mirostat 2.0"],"name":"mirostat","display_name":"Mirostat","advanced":true,"dynamic":false,"info":"Enable/disable Mirostat sampling for controlling perplexity.","load_from_db":false,"title_case":false,"input_types":["Text"]},"mirostat_eta":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_eta","display_name":"Mirostat Eta","advanced":true,"dynamic":false,"info":"Learning rate for Mirostat algorithm. (Default: 0.1)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"mirostat_tau":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_tau","display_name":"Mirostat Tau","advanced":true,"dynamic":false,"info":"Controls the balance between coherence and diversity of the output. (Default: 5.0)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"model":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"llama3:8b","fileTypes":[],"file_path":"","password":false,"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"Refer to https://ollama.ai/library for more models.","load_from_db":false,"title_case":false,"input_types":["Text"]},"num_ctx":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_ctx","display_name":"Context Window Size","advanced":true,"dynamic":false,"info":"Size of the context window for generating tokens. (Default: 2048)","load_from_db":false,"title_case":false},"num_gpu":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_gpu","display_name":"Number of GPUs","advanced":true,"dynamic":false,"info":"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)","load_from_db":false,"title_case":false},"num_thread":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_thread","display_name":"Number of Threads","advanced":true,"dynamic":false,"info":"Number of threads to use during computation. (Default: detected for optimal performance)","load_from_db":false,"title_case":false},"repeat_last_n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_last_n","display_name":"Repeat Last N","advanced":true,"dynamic":false,"info":"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)","load_from_db":false,"title_case":false},"repeat_penalty":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_penalty","display_name":"Repeat Penalty","advanced":true,"dynamic":false,"info":"Penalty for repetitions in generated text. (Default: 1.1)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":false,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system","display_name":"System","advanced":true,"dynamic":false,"info":"System to use for generating text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"0","fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Controls the creativity of model responses.","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":true,"dynamic":false,"info":"Template to use for generating text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"tfs_z":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tfs_z","display_name":"TFS Z","advanced":true,"dynamic":false,"info":"Tail free sampling value. (Default: 1)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"timeout":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"timeout","display_name":"Timeout","advanced":true,"dynamic":false,"info":"Timeout for the request stream.","load_from_db":false,"title_case":false},"top_k":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_k","display_name":"Top K","advanced":true,"dynamic":false,"info":"Limits token selection to top K. (Default: 40)","load_from_db":false,"title_case":false},"top_p":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_p","display_name":"Top P","advanced":true,"dynamic":false,"info":"Works together with top-k. (Default: 0.9)","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"verbose":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"verbose","display_name":"Verbose","advanced":false,"dynamic":false,"info":"Whether to print out response text.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generate text using Ollama Local LLMs.","icon":"Ollama","base_classes":["object","str","Text"],"display_name":"Ollama","documentation":"","custom_fields":{"base_url":null,"model":null,"input_value":null,"mirostat":null,"mirostat_eta":null,"mirostat_tau":null,"repeat_last_n":null,"verbose":null,"cache":null,"num_ctx":null,"num_gpu":null,"format":null,"metadata":null,"num_thread":null,"repeat_penalty":null,"stop":null,"system":null,"tags":null,"temperature":null,"template":null,"tfs_z":null,"timeout":null,"top_k":null,"top_p":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["base_url","model","temperature","cache","callback_manager","callbacks","format","metadata","mirostat","mirostat_eta","mirostat_tau","num_ctx","num_gpu","num_thread","repeat_last_n","repeat_penalty","tfs_z","timeout","top_k","top_p","verbose","tags","stop","system","template","input_value","system_message","stream"],"beta":false},"id":"OllamaModel-ThRiU"},"selected":false,"width":384,"height":621,"positionAbsolute":{"x":-73.7630007481905,"y":-65.49065680954584},"dragging":false},{"id":"AgentInitializer-inEJM","type":"genericNode","position":{"x":-2272.590955924553,"y":380.552854938735},"data":{"type":"AgentInitializer","node":{"template":{"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"Language Model","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"memory":{"type":"BaseChatMemory","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"memory","display_name":"Memory","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tools":{"type":"Tool","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tools","display_name":"Tools","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"agent":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"value":"zero-shot-react-description","fileTypes":[],"file_path":"","password":false,"options":["zero-shot-react-description","react-docstore","self-ask-with-search","conversational-react-description","chat-zero-shot-react-description","chat-conversational-react-description","structured-chat-zero-shot-react-description","openai-functions","openai-multi-functions","JsonAgent","CSVAgent","VectorStoreAgent","VectorStoreRouterAgent","SQLAgent"],"name":"agent","display_name":"Agent Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Callable, List, Optional, Union\n\nfrom langchain.agents import AgentExecutor, AgentType, initialize_agent, types\n\nfrom langflow.field_typing import BaseChatMemory, BaseLanguageModel, Tool\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass AgentInitializerComponent(CustomComponent):\n    display_name: str = \"Agent Initializer\"\n    description: str = \"Initialize a Langchain Agent.\"\n    documentation: str = \"https://python.langchain.com/docs/modules/agents/agent_types/\"\n\n    def build_config(self):\n        agents = list(types.AGENT_TO_CLASS.keys())\n        # field_type and required are optional\n        return {\n            \"agent\": {\"options\": agents, \"value\": agents[0], \"display_name\": \"Agent Type\"},\n            \"max_iterations\": {\"display_name\": \"Max Iterations\", \"value\": 10},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"tools\": {\"display_name\": \"Tools\"},\n            \"llm\": {\"display_name\": \"Language Model\"},\n            \"code\": {\"advanced\": True},\n        }\n\n    def build(\n        self,\n        agent: str,\n        llm: BaseLanguageModel,\n        tools: List[Tool],\n        max_iterations: int,\n        memory: Optional[BaseChatMemory] = None,\n    ) -> Union[AgentExecutor, Callable]:\n        agent = AgentType(agent)\n        if memory:\n            return initialize_agent(\n                tools=tools,\n                llm=llm,\n                agent=agent,\n                memory=memory,\n                return_intermediate_steps=True,\n                handle_parsing_errors=True,\n                max_iterations=max_iterations,\n            )\n        return initialize_agent(\n            tools=tools,\n            llm=llm,\n            agent=agent,\n            return_intermediate_steps=True,\n            handle_parsing_errors=True,\n            max_iterations=max_iterations,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_iterations":{"type":"int","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":10,"fileTypes":[],"file_path":"","password":false,"name":"max_iterations","display_name":"Max Iterations","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Initialize a Langchain Agent.","base_classes":["AgentExecutor","Callable","Chain","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"Agent Initializer","documentation":"https://python.langchain.com/docs/modules/agents/agent_types/","custom_fields":{"agent":null,"llm":null,"tools":null,"max_iterations":null,"memory":null},"output_types":["AgentExecutor","Callable"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"AgentInitializer-inEJM"},"selected":false,"width":384,"height":519,"positionAbsolute":{"x":-2272.590955924553,"y":380.552854938735},"dragging":false},{"id":"OllamaLLMSpecs-H7xyV","type":"genericNode","position":{"x":-3300.849897613473,"y":262.6596264921521},"data":{"type":"OllamaLLMSpecs","node":{"template":{"base_url":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"base_url","display_name":"Base URL","advanced":false,"dynamic":false,"info":"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langflow.field_typing import BaseLanguageModel\nfrom langchain_community.llms.ollama import Ollama\n\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass OllamaLLM(CustomComponent):\n    display_name = \"Ollama\"\n    description = \"Local LLM with Ollama.\"\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate influencing the algorithm's response to feedback.\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls balance between coherence and diversity.\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating the next token.\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation.\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation.\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"Sets how far back the model looks to prevent repetition.\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling to reduce impact of less probable tokens.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K for reducing nonsense generation.\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"int\",\n                \"info\": \"Works with top-k to control diversity of generated text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        temperature: Optional[float],\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        num_thread: Optional[int] = None,\n        repeat_last_n: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        tfs_z: Optional[float] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n    ) -> BaseLanguageModel:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        try:\n            llm = Ollama(\n                base_url=base_url,\n                model=model,\n                mirostat=mirostat_value,\n                mirostat_eta=mirostat_eta,\n                mirostat_tau=mirostat_tau,\n                num_ctx=num_ctx,\n                num_gpu=num_gpu,\n                num_thread=num_thread,\n                repeat_last_n=repeat_last_n,\n                repeat_penalty=repeat_penalty,\n                temperature=temperature,\n                stop=stop,\n                tfs_z=tfs_z,\n                top_k=top_k,\n                top_p=top_p,\n            )\n\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama.\") from e\n\n        return llm\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"mirostat":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Disabled","fileTypes":[],"file_path":"","password":false,"options":["Disabled","Mirostat","Mirostat 2.0"],"name":"mirostat","display_name":"Mirostat","advanced":true,"dynamic":false,"info":"Enable/disable Mirostat sampling for controlling perplexity.","load_from_db":false,"title_case":false,"input_types":["Text"]},"mirostat_eta":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_eta","display_name":"Mirostat Eta","advanced":true,"dynamic":false,"info":"Learning rate influencing the algorithm's response to feedback.","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"mirostat_tau":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_tau","display_name":"Mirostat Tau","advanced":true,"dynamic":false,"info":"Controls balance between coherence and diversity.","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"model":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"llama2","fileTypes":[],"file_path":"","password":false,"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"Refer to https://ollama.ai/library for more models.","load_from_db":false,"title_case":false,"input_types":["Text"]},"num_ctx":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_ctx","display_name":"Context Window Size","advanced":true,"dynamic":false,"info":"Size of the context window for generating the next token.","load_from_db":false,"title_case":false},"num_gpu":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_gpu","display_name":"Number of GPUs","advanced":true,"dynamic":false,"info":"Number of GPUs to use for computation.","load_from_db":false,"title_case":false},"num_thread":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_thread","display_name":"Number of Threads","advanced":true,"dynamic":false,"info":"Number of threads to use during computation.","load_from_db":false,"title_case":false},"repeat_last_n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_last_n","display_name":"Repeat Last N","advanced":true,"dynamic":false,"info":"Sets how far back the model looks to prevent repetition.","load_from_db":false,"title_case":false},"repeat_penalty":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_penalty","display_name":"Repeat Penalty","advanced":true,"dynamic":false,"info":"Penalty for repetitions in generated text.","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"stop":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"stop","display_name":"Stop Tokens","advanced":true,"dynamic":false,"info":"List of tokens to signal the model to stop generating text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.8,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Controls the creativity of model responses.","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"tfs_z":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tfs_z","display_name":"TFS Z","advanced":true,"dynamic":false,"info":"Tail free sampling to reduce impact of less probable tokens.","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"top_k":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_k","display_name":"Top K","advanced":true,"dynamic":false,"info":"Limits token selection to top K for reducing nonsense generation.","load_from_db":false,"title_case":false},"top_p":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_p","display_name":"Top P","advanced":true,"dynamic":false,"info":"Works with top-k to control diversity of generated text.","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Local LLM with Ollama.","base_classes":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"Ollama","documentation":"","custom_fields":{"base_url":null,"model":null,"temperature":null,"mirostat":null,"mirostat_eta":null,"mirostat_tau":null,"num_ctx":null,"num_gpu":null,"num_thread":null,"repeat_last_n":null,"repeat_penalty":null,"stop":null,"tfs_z":null,"top_k":null,"top_p":null},"output_types":["BaseLanguageModel"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"OllamaLLMSpecs-H7xyV"},"selected":false,"width":384,"height":469,"positionAbsolute":{"x":-3300.849897613473,"y":262.6596264921521},"dragging":false},{"id":"VectorStoreRouterToolkit-4DAtd","type":"genericNode","position":{"x":-2775.814034901775,"y":886.0759114891954},"data":{"type":"VectorStoreRouterToolkit","node":{"template":{"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"LLM","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"vectorstores":{"type":"VectorStoreInfo","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"vectorstores","display_name":"Vector Stores","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Union\n\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo, VectorStoreRouterToolkit\n\nfrom langflow.field_typing import BaseLanguageModel, Tool\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass VectorStoreRouterToolkitComponent(CustomComponent):\n    display_name = \"VectorStoreRouterToolkit\"\n    description = \"Toolkit for routing between Vector Stores.\"\n\n    def build_config(self):\n        return {\n            \"vectorstores\": {\"display_name\": \"Vector Stores\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n        }\n\n    def build(\n        self, vectorstores: List[VectorStoreInfo], llm: BaseLanguageModel\n    ) -> Union[Tool, VectorStoreRouterToolkit]:\n        print(\"vectorstores\", vectorstores)\n        print(\"llm\", llm)\n        return VectorStoreRouterToolkit(vectorstores=vectorstores, llm=llm)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Toolkit for routing between Vector Stores.","base_classes":["BaseTool","BaseToolkit","Generic","object","Runnable","RunnableSerializable","Serializable","Tool","VectorStoreRouterToolkit"],"display_name":"VectorStoreRouterToolkit","documentation":"","custom_fields":{"vectorstores":null,"llm":null},"output_types":["Tool","VectorStoreRouterToolkit"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"VectorStoreRouterToolkit-4DAtd"},"selected":false,"width":384,"height":291,"positionAbsolute":{"x":-2775.814034901775,"y":886.0759114891954},"dragging":false},{"id":"VectorStoreInfo-1FplG","type":"genericNode","position":{"x":-3365.5910532161192,"y":902.9457451489682},"data":{"type":"VectorStoreInfo","node":{"template":{"vectorstore":{"type":"VectorStore","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"vectorstore","display_name":"VectorStore","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo\nfrom langchain_community.vectorstores import VectorStore\n\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass VectorStoreInfoComponent(CustomComponent):\n    display_name = \"VectorStoreInfo\"\n    description = \"Information about a VectorStore\"\n\n    def build_config(self):\n        return {\n            \"vectorstore\": {\"display_name\": \"VectorStore\"},\n            \"description\": {\"display_name\": \"Description\", \"multiline\": True},\n            \"name\": {\"display_name\": \"Name\"},\n        }\n\n    def build(\n        self,\n        vectorstore: VectorStore,\n        description: str,\n        name: str,\n    ) -> VectorStoreInfo:\n        return VectorStoreInfo(vectorstore=vectorstore, description=description, name=name)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"description":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"description","display_name":"Description","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"This is the vector store for the agents to access"},"name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"name","display_name":"Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Information about a VectorStore","base_classes":["VectorStoreInfo"],"display_name":"VectorStoreInfo","documentation":"","custom_fields":{"vectorstore":null,"description":null,"name":null},"output_types":["VectorStoreInfo"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"VectorStoreInfo-1FplG"},"selected":false,"width":384,"height":431,"positionAbsolute":{"x":-3365.5910532161192,"y":902.9457451489682},"dragging":false},{"id":"RunnableExecutor-RSDrm","type":"genericNode","position":{"x":-1793.4023613719903,"y":110.9257398854113},"data":{"type":"RunnableExecutor","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Inputs","advanced":false,"dynamic":false,"info":"The inputs to pass to the runnable.","load_from_db":false,"title_case":false,"input_types":["Text"]},"runnable":{"type":"Runnable","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"runnable","display_name":"Runnable","advanced":false,"input_types":["Chain","AgentExecutor","Agent","Runnable"],"dynamic":false,"info":"The runnable to execute.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.runnables import Runnable\n\nfrom langflow.field_typing import Text\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass RunnableExecComponent(CustomComponent):\n    description = \"Execute a runnable. It will try to guess the input and output keys.\"\n    display_name = \"Runnable Executor\"\n    beta: bool = True\n    field_order = [\n        \"input_key\",\n        \"output_key\",\n        \"input_value\",\n        \"runnable\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_key\": {\n                \"display_name\": \"Input Key\",\n                \"info\": \"The key to use for the input.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"The inputs to pass to the runnable.\",\n            },\n            \"runnable\": {\n                \"display_name\": \"Runnable\",\n                \"info\": \"The runnable to execute.\",\n                \"input_types\": [\"Chain\", \"AgentExecutor\", \"Agent\", \"Runnable\"],\n            },\n            \"output_key\": {\n                \"display_name\": \"Output Key\",\n                \"info\": \"The key to use for the output.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_output(self, result, input_key, output_key):\n        \"\"\"\n        Retrieves the output value from the given result dictionary based on the specified input and output keys.\n\n        Args:\n            result (dict): The result dictionary containing the output value.\n            input_key (str): The key used to retrieve the input value from the result dictionary.\n            output_key (str): The key used to retrieve the output value from the result dictionary.\n\n        Returns:\n            tuple: A tuple containing the output value and the status message.\n\n        \"\"\"\n        possible_output_keys = [\"answer\", \"response\", \"output\", \"result\", \"text\"]\n        status = \"\"\n        result_value = None\n\n        if output_key in result:\n            result_value = result.get(output_key)\n        elif len(result) == 2 and input_key in result:\n            # get the other key from the result dict\n            other_key = [k for k in result if k != input_key][0]\n            if other_key == output_key:\n                result_value = result.get(output_key)\n            else:\n                status += f\"Warning: The output key is not '{output_key}'. The output key is '{other_key}'.\"\n                result_value = result.get(other_key)\n        elif len(result) == 1:\n            result_value = list(result.values())[0]\n        elif any(k in result for k in possible_output_keys):\n            for key in possible_output_keys:\n                if key in result:\n                    result_value = result.get(key)\n                    status += f\"Output key: '{key}'.\"\n                    break\n            if result_value is None:\n                result_value = result\n                status += f\"Warning: The output key is not '{output_key}'.\"\n        else:\n            result_value = result\n            status += f\"Warning: The output key is not '{output_key}'.\"\n\n        return result_value, status\n\n    def get_input_dict(self, runnable, input_key, input_value):\n        \"\"\"\n        Returns a dictionary containing the input key-value pair for the given runnable.\n\n        Args:\n            runnable: The runnable object.\n            input_key: The key for the input value.\n            input_value: The value for the input key.\n\n        Returns:\n            input_dict: A dictionary containing the input key-value pair.\n            status: A status message indicating if the input key is not in the runnable's input keys.\n        \"\"\"\n        input_dict = {}\n        status = \"\"\n        if hasattr(runnable, \"input_keys\"):\n            # Check if input_key is in the runnable's input_keys\n            if input_key in runnable.input_keys:\n                input_dict[input_key] = input_value\n            else:\n                input_dict = {k: input_value for k in runnable.input_keys}\n                status = f\"Warning: The input key is not '{input_key}'. The input key is '{runnable.input_keys}'.\"\n        return input_dict, status\n\n    def build(\n        self,\n        input_value: Text,\n        runnable: Runnable,\n        input_key: str = \"input\",\n        output_key: str = \"output\",\n    ) -> Text:\n        input_dict, status = self.get_input_dict(runnable, input_key, input_value)\n        result = runnable.invoke(input_dict)\n        result_value, _status = self.get_output(result, input_key, output_key)\n        status += _status\n        status += f\"\\n\\nOutput: {result_value}\\n\\nRaw Output: {result}\"\n        self.status = status\n        return result_value\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"input","fileTypes":[],"file_path":"","password":false,"name":"input_key","display_name":"Input Key","advanced":true,"dynamic":false,"info":"The key to use for the input.","load_from_db":false,"title_case":false,"input_types":["Text"]},"output_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"output","fileTypes":[],"file_path":"","password":false,"name":"output_key","display_name":"Output Key","advanced":true,"dynamic":false,"info":"The key to use for the output.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Execute a runnable. It will try to guess the input and output keys.","base_classes":["object","str","Text"],"display_name":"Runnable Executor","documentation":"","custom_fields":{"input_value":null,"runnable":null,"input_key":null,"output_key":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["input_key","output_key","input_value","runnable"],"beta":true},"id":"RunnableExecutor-RSDrm"},"selected":false,"width":384,"height":357,"positionAbsolute":{"x":-1793.4023613719903,"y":110.9257398854113},"dragging":false},{"id":"LanguageRecursiveTextSplitter-S1YTu","type":"genericNode","position":{"x":969.3914710398193,"y":-65.74970192960633},"data":{"type":"LanguageRecursiveTextSplitter","node":{"template":{"inputs":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Input","advanced":false,"input_types":["Document","Record"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"chunk_overlap":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":200,"fileTypes":[],"file_path":"","password":false,"name":"chunk_overlap","display_name":"Chunk Overlap","advanced":false,"dynamic":false,"info":"The amount of overlap between chunks.","load_from_db":false,"title_case":false},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":false,"dynamic":false,"info":"The maximum length of each chunk.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langchain.text_splitter import Language\n\nfrom langflow.interface.custom.custom_component import CustomComponent\nfrom langflow.schema.schema import Record\n\n\nclass LanguageRecursiveTextSplitterComponent(CustomComponent):\n    display_name: str = \"Language Recursive Text Splitter\"\n    description: str = \"Split text into chunks of a specified length based on language.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter\"\n\n    def build_config(self):\n        options = [x.value for x in Language]\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"separator_type\": {\n                \"display_name\": \"Separator Type\",\n                \"info\": \"The type of separator to use.\",\n                \"field_type\": \"str\",\n                \"options\": options,\n                \"value\": \"Python\",\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": \"The characters to split on.\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        inputs: List[Record],\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n        separator_type: str = \"Python\",\n    ) -> list[Record]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n        from langchain.text_splitter import RecursiveCharacterTextSplitter\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n\n        splitter = RecursiveCharacterTextSplitter.from_language(\n            language=Language(separator_type),\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = splitter.split_documents(documents)\n        records = self.to_records(docs)\n        return records\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"separator_type":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Python","fileTypes":[],"file_path":"","password":false,"options":["cpp","go","java","kotlin","js","ts","php","proto","python","rst","ruby","rust","scala","swift","markdown","latex","html","sol","csharp","cobol","c","lua","perl"],"name":"separator_type","display_name":"Separator Type","advanced":false,"dynamic":false,"info":"The type of separator to use.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Split text into chunks of a specified length based on language.","base_classes":["Record"],"display_name":"Language Recursive Text Splitter","documentation":"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter","custom_fields":{"inputs":null,"chunk_size":null,"chunk_overlap":null,"separator_type":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"LanguageRecursiveTextSplitter-S1YTu"},"selected":false,"width":384,"height":529,"positionAbsolute":{"x":969.3914710398193,"y":-65.74970192960633},"dragging":false},{"id":"ChatOutput-uZVOb","type":"genericNode","position":{"x":395.3809070924914,"y":249.89491401085564},"data":{"type":"ChatOutput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"In case of Message being a Record, this template will be used to convert it to text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["object","Record","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null,"record_template":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-uZVOb"},"selected":false,"width":384,"height":383,"positionAbsolute":{"x":395.3809070924914,"y":249.89491401085564},"dragging":false},{"id":"ChatInput-ZBw8y","type":"genericNode","position":{"x":-2979.870401369768,"y":-322.1035918088397},"data":{"type":"ChatInput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Message\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n    ) -> Union[Text, Record]:\n        return super().build_no_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["object","Record","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-ZBw8y"},"selected":false,"width":384,"height":375,"positionAbsolute":{"x":-2979.870401369768,"y":-322.1035918088397},"dragging":false},{"id":"VectorStoreRetriever-qjsTT","type":"genericNode","position":{"x":1922.2367532421842,"y":239.17714140776917},"data":{"type":"VectorStoreRetriever","node":{"template":{"vectorstore":{"type":"VectorStore","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"vectorstore","display_name":"Vector Store","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.vectorstores import VectorStoreRetriever\n\nfrom langflow.field_typing import VectorStore\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass VectoStoreRetrieverComponent(CustomComponent):\n    display_name = \"VectorStore Retriever\"\n    description = \"A vector store retriever\"\n\n    def build_config(self):\n        return {\n            \"vectorstore\": {\"display_name\": \"Vector Store\", \"type\": VectorStore},\n        }\n\n    def build(self, vectorstore: VectorStore) -> VectorStoreRetriever:\n        return vectorstore.as_retriever()\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"A vector store retriever","base_classes":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStoreRetriever"],"display_name":"VectorStore Retriever","documentation":"","custom_fields":{"vectorstore":null},"output_types":["VectorStoreRetriever"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"VectorStoreRetriever-qjsTT"},"selected":false,"width":384,"height":243,"positionAbsolute":{"x":1922.2367532421842,"y":239.17714140776917},"dragging":false},{"id":"RunnableExecutor-fNcvp","type":"genericNode","position":{"x":2678.9121444386365,"y":250.67094481834818},"data":{"type":"RunnableExecutor","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Inputs","advanced":false,"dynamic":false,"info":"The inputs to pass to the runnable.","load_from_db":false,"title_case":false,"input_types":["Text"]},"runnable":{"type":"Runnable","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"runnable","display_name":"Runnable","advanced":false,"input_types":["Chain","AgentExecutor","Agent","Runnable"],"dynamic":false,"info":"The runnable to execute.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.runnables import Runnable\n\nfrom langflow.field_typing import Text\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass RunnableExecComponent(CustomComponent):\n    description = \"Execute a runnable. It will try to guess the input and output keys.\"\n    display_name = \"Runnable Executor\"\n    beta: bool = True\n    field_order = [\n        \"input_key\",\n        \"output_key\",\n        \"input_value\",\n        \"runnable\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_key\": {\n                \"display_name\": \"Input Key\",\n                \"info\": \"The key to use for the input.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"The inputs to pass to the runnable.\",\n            },\n            \"runnable\": {\n                \"display_name\": \"Runnable\",\n                \"info\": \"The runnable to execute.\",\n                \"input_types\": [\"Chain\", \"AgentExecutor\", \"Agent\", \"Runnable\"],\n            },\n            \"output_key\": {\n                \"display_name\": \"Output Key\",\n                \"info\": \"The key to use for the output.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_output(self, result, input_key, output_key):\n        \"\"\"\n        Retrieves the output value from the given result dictionary based on the specified input and output keys.\n\n        Args:\n            result (dict): The result dictionary containing the output value.\n            input_key (str): The key used to retrieve the input value from the result dictionary.\n            output_key (str): The key used to retrieve the output value from the result dictionary.\n\n        Returns:\n            tuple: A tuple containing the output value and the status message.\n\n        \"\"\"\n        possible_output_keys = [\"answer\", \"response\", \"output\", \"result\", \"text\"]\n        status = \"\"\n        result_value = None\n\n        if output_key in result:\n            result_value = result.get(output_key)\n        elif len(result) == 2 and input_key in result:\n            # get the other key from the result dict\n            other_key = [k for k in result if k != input_key][0]\n            if other_key == output_key:\n                result_value = result.get(output_key)\n            else:\n                status += f\"Warning: The output key is not '{output_key}'. The output key is '{other_key}'.\"\n                result_value = result.get(other_key)\n        elif len(result) == 1:\n            result_value = list(result.values())[0]\n        elif any(k in result for k in possible_output_keys):\n            for key in possible_output_keys:\n                if key in result:\n                    result_value = result.get(key)\n                    status += f\"Output key: '{key}'.\"\n                    break\n            if result_value is None:\n                result_value = result\n                status += f\"Warning: The output key is not '{output_key}'.\"\n        else:\n            result_value = result\n            status += f\"Warning: The output key is not '{output_key}'.\"\n\n        return result_value, status\n\n    def get_input_dict(self, runnable, input_key, input_value):\n        \"\"\"\n        Returns a dictionary containing the input key-value pair for the given runnable.\n\n        Args:\n            runnable: The runnable object.\n            input_key: The key for the input value.\n            input_value: The value for the input key.\n\n        Returns:\n            input_dict: A dictionary containing the input key-value pair.\n            status: A status message indicating if the input key is not in the runnable's input keys.\n        \"\"\"\n        input_dict = {}\n        status = \"\"\n        if hasattr(runnable, \"input_keys\"):\n            # Check if input_key is in the runnable's input_keys\n            if input_key in runnable.input_keys:\n                input_dict[input_key] = input_value\n            else:\n                input_dict = {k: input_value for k in runnable.input_keys}\n                status = f\"Warning: The input key is not '{input_key}'. The input key is '{runnable.input_keys}'.\"\n        return input_dict, status\n\n    def build(\n        self,\n        input_value: Text,\n        runnable: Runnable,\n        input_key: str = \"input\",\n        output_key: str = \"output\",\n    ) -> Text:\n        input_dict, status = self.get_input_dict(runnable, input_key, input_value)\n        result = runnable.invoke(input_dict)\n        result_value, _status = self.get_output(result, input_key, output_key)\n        status += _status\n        status += f\"\\n\\nOutput: {result_value}\\n\\nRaw Output: {result}\"\n        self.status = status\n        return result_value\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"input","fileTypes":[],"file_path":"","password":false,"name":"input_key","display_name":"Input Key","advanced":true,"dynamic":false,"info":"The key to use for the input.","load_from_db":false,"title_case":false,"input_types":["Text"]},"output_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"output","fileTypes":[],"file_path":"","password":false,"name":"output_key","display_name":"Output Key","advanced":true,"dynamic":false,"info":"The key to use for the output.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Execute a runnable. It will try to guess the input and output keys.","base_classes":["object","str","Text"],"display_name":"Runnable Executor","documentation":"","custom_fields":{"input_value":null,"runnable":null,"input_key":null,"output_key":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["input_key","output_key","input_value","runnable"],"beta":true},"id":"RunnableExecutor-fNcvp"},"selected":false,"width":384,"height":357,"positionAbsolute":{"x":2678.9121444386365,"y":250.67094481834818},"dragging":false},{"id":"TextInput-zIhwT","type":"genericNode","position":{"x":2208.8155849459513,"y":697.0136439291667},"data":{"type":"TextInput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Value","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as input.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Text Input","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"TextInput-zIhwT"},"selected":false,"width":384,"height":289,"positionAbsolute":{"x":2208.8155849459513,"y":697.0136439291667},"dragging":false},{"id":"ChatOutput-uyk8S","type":"genericNode","position":{"x":3237.5109901927735,"y":455.64377230700734},"data":{"type":"ChatOutput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"In case of Message being a Record, this template will be used to convert it to text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["object","Record","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null,"record_template":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-uyk8S"},"selected":false,"width":384,"height":383,"positionAbsolute":{"x":3237.5109901927735,"y":455.64377230700734},"dragging":false}],"edges":[{"source":"OllamaEmbeddings-G77ye","sourceHandle":"{baseClasses:[Embeddings],dataType:OllamaEmbeddings,id:OllamaEmbeddings-G77ye}","target":"MongoDBAtlasVectorSearch-PY4MJ","targetHandle":"{fieldName:embedding,id:MongoDBAtlasVectorSearch-PY4MJ,inputTypes:null,type:Embeddings}","data":{"targetHandle":{"fieldName":"embedding","id":"MongoDBAtlasVectorSearch-PY4MJ","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OllamaEmbeddings","id":"OllamaEmbeddings-G77ye"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OllamaEmbeddings-G77ye{baseClasses:[Embeddings],dataType:OllamaEmbeddings,id:OllamaEmbeddings-G77ye}-MongoDBAtlasVectorSearch-PY4MJ{fieldName:embedding,id:MongoDBAtlasVectorSearch-PY4MJ,inputTypes:null,type:Embeddings}"},{"source":"TextInput-axe6h","sourceHandle":"{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-axe6h}","target":"Prompt-qz9Jn","targetHandle":"{fieldName:collection_name,id:Prompt-qz9Jn,inputTypes:[Document,Record,Text],type:str}","data":{"targetHandle":{"fieldName":"collection_name","id":"Prompt-qz9Jn","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-axe6h"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-TextInput-axe6h{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-axe6h}-Prompt-qz9Jn{fieldName:collection_name,id:Prompt-qz9Jn,inputTypes:[Document,Record,Text],type:str}"},{"source":"TextInput-9uD8V","sourceHandle":"{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-9uD8V}","target":"Prompt-qz9Jn","targetHandle":"{fieldName:data_field_desc,id:Prompt-qz9Jn,inputTypes:[Document,Record,Text],type:str}","data":{"targetHandle":{"fieldName":"data_field_desc","id":"Prompt-qz9Jn","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-9uD8V"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-TextInput-9uD8V{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-9uD8V}-Prompt-qz9Jn{fieldName:data_field_desc,id:Prompt-qz9Jn,inputTypes:[Document,Record,Text],type:str}"},{"source":"OllamaEmbeddings-G77ye","sourceHandle":"{baseClasses:[Embeddings],dataType:OllamaEmbeddings,id:OllamaEmbeddings-G77ye}","target":"MongoDBAtlasVector-QL9hJ","targetHandle":"{fieldName:embedding,id:MongoDBAtlasVector-QL9hJ,inputTypes:null,type:Embeddings}","data":{"targetHandle":{"fieldName":"embedding","id":"MongoDBAtlasVector-QL9hJ","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OllamaEmbeddings","id":"OllamaEmbeddings-G77ye"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OllamaEmbeddings-G77ye{baseClasses:[Embeddings],dataType:OllamaEmbeddings,id:OllamaEmbeddings-G77ye}-MongoDBAtlasVector-QL9hJ{fieldName:embedding,id:MongoDBAtlasVector-QL9hJ,inputTypes:null,type:Embeddings}"},{"source":"MongoDBAtlasVectorSearch-PY4MJ","sourceHandle":"{baseClasses:[Record],dataType:MongoDBAtlasVectorSearch,id:MongoDBAtlasVectorSearch-PY4MJ}","target":"LanguageRecursiveTextSplitter-xQXxD","targetHandle":"{fieldName:inputs,id:LanguageRecursiveTextSplitter-xQXxD,inputTypes:[Document,Record],type:Record}","data":{"targetHandle":{"fieldName":"inputs","id":"LanguageRecursiveTextSplitter-xQXxD","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"MongoDBAtlasVectorSearch","id":"MongoDBAtlasVectorSearch-PY4MJ"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-MongoDBAtlasVectorSearch-PY4MJ{baseClasses:[Record],dataType:MongoDBAtlasVectorSearch,id:MongoDBAtlasVectorSearch-PY4MJ}-LanguageRecursiveTextSplitter-xQXxD{fieldName:inputs,id:LanguageRecursiveTextSplitter-xQXxD,inputTypes:[Document,Record],type:Record}"},{"source":"OllamaLLMSpecs-H7xyV","sourceHandle":"{baseClasses:[BaseLanguageModel,Generic,object,Runnable,RunnableSerializable,Serializable],dataType:OllamaLLMSpecs,id:OllamaLLMSpecs-H7xyV}","target":"AgentInitializer-inEJM","targetHandle":"{fieldName:llm,id:AgentInitializer-inEJM,inputTypes:null,type:BaseLanguageModel}","data":{"targetHandle":{"fieldName":"llm","id":"AgentInitializer-inEJM","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"OllamaLLMSpecs","id":"OllamaLLMSpecs-H7xyV"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OllamaLLMSpecs-H7xyV{baseClasses:[BaseLanguageModel,Generic,object,Runnable,RunnableSerializable,Serializable],dataType:OllamaLLMSpecs,id:OllamaLLMSpecs-H7xyV}-AgentInitializer-inEJM{fieldName:llm,id:AgentInitializer-inEJM,inputTypes:null,type:BaseLanguageModel}"},{"source":"OllamaLLMSpecs-H7xyV","sourceHandle":"{baseClasses:[BaseLanguageModel,Generic,object,Runnable,RunnableSerializable,Serializable],dataType:OllamaLLMSpecs,id:OllamaLLMSpecs-H7xyV}","target":"VectorStoreRouterToolkit-4DAtd","targetHandle":"{fieldName:llm,id:VectorStoreRouterToolkit-4DAtd,inputTypes:null,type:BaseLanguageModel}","data":{"targetHandle":{"fieldName":"llm","id":"VectorStoreRouterToolkit-4DAtd","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"OllamaLLMSpecs","id":"OllamaLLMSpecs-H7xyV"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OllamaLLMSpecs-H7xyV{baseClasses:[BaseLanguageModel,Generic,object,Runnable,RunnableSerializable,Serializable],dataType:OllamaLLMSpecs,id:OllamaLLMSpecs-H7xyV}-VectorStoreRouterToolkit-4DAtd{fieldName:llm,id:VectorStoreRouterToolkit-4DAtd,inputTypes:null,type:BaseLanguageModel}"},{"source":"VectorStoreInfo-1FplG","sourceHandle":"{baseClasses:[VectorStoreInfo],dataType:VectorStoreInfo,id:VectorStoreInfo-1FplG}","target":"VectorStoreRouterToolkit-4DAtd","targetHandle":"{fieldName:vectorstores,id:VectorStoreRouterToolkit-4DAtd,inputTypes:null,type:VectorStoreInfo}","data":{"targetHandle":{"fieldName":"vectorstores","id":"VectorStoreRouterToolkit-4DAtd","inputTypes":null,"type":"VectorStoreInfo"},"sourceHandle":{"baseClasses":["VectorStoreInfo"],"dataType":"VectorStoreInfo","id":"VectorStoreInfo-1FplG"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-VectorStoreInfo-1FplG{baseClasses:[VectorStoreInfo],dataType:VectorStoreInfo,id:VectorStoreInfo-1FplG}-VectorStoreRouterToolkit-4DAtd{fieldName:vectorstores,id:VectorStoreRouterToolkit-4DAtd,inputTypes:null,type:VectorStoreInfo}"},{"source":"VectorStoreRouterToolkit-4DAtd","sourceHandle":"{baseClasses:[BaseTool,BaseToolkit,Generic,object,Runnable,RunnableSerializable,Serializable,Tool,VectorStoreRouterToolkit],dataType:VectorStoreRouterToolkit,id:VectorStoreRouterToolkit-4DAtd}","target":"AgentInitializer-inEJM","targetHandle":"{fieldName:tools,id:AgentInitializer-inEJM,inputTypes:null,type:Tool}","data":{"targetHandle":{"fieldName":"tools","id":"AgentInitializer-inEJM","inputTypes":null,"type":"Tool"},"sourceHandle":{"baseClasses":["BaseTool","BaseToolkit","Generic","object","Runnable","RunnableSerializable","Serializable","Tool","VectorStoreRouterToolkit"],"dataType":"VectorStoreRouterToolkit","id":"VectorStoreRouterToolkit-4DAtd"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-VectorStoreRouterToolkit-4DAtd{baseClasses:[BaseTool,BaseToolkit,Generic,object,Runnable,RunnableSerializable,Serializable,Tool,VectorStoreRouterToolkit],dataType:VectorStoreRouterToolkit,id:VectorStoreRouterToolkit-4DAtd}-AgentInitializer-inEJM{fieldName:tools,id:AgentInitializer-inEJM,inputTypes:null,type:Tool}"},{"source":"AgentInitializer-inEJM","sourceHandle":"{baseClasses:[AgentExecutor,Callable,Chain,Generic,object,Runnable,RunnableSerializable,Serializable],dataType:AgentInitializer,id:AgentInitializer-inEJM}","target":"RunnableExecutor-RSDrm","targetHandle":"{fieldName:runnable,id:RunnableExecutor-RSDrm,inputTypes:[Chain,AgentExecutor,Agent,Runnable],type:Runnable}","data":{"targetHandle":{"fieldName":"runnable","id":"RunnableExecutor-RSDrm","inputTypes":["Chain","AgentExecutor","Agent","Runnable"],"type":"Runnable"},"sourceHandle":{"baseClasses":["AgentExecutor","Callable","Chain","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"AgentInitializer","id":"AgentInitializer-inEJM"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-AgentInitializer-inEJM{baseClasses:[AgentExecutor,Callable,Chain,Generic,object,Runnable,RunnableSerializable,Serializable],dataType:AgentInitializer,id:AgentInitializer-inEJM}-RunnableExecutor-RSDrm{fieldName:runnable,id:RunnableExecutor-RSDrm,inputTypes:[Chain,AgentExecutor,Agent,Runnable],type:Runnable}"},{"source":"Prompt-qz9Jn","sourceHandle":"{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-qz9Jn}","target":"OllamaModel-ThRiU","targetHandle":"{fieldName:input_value,id:OllamaModel-ThRiU,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"OllamaModel-ThRiU","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-qz9Jn"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-Prompt-qz9Jn{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-qz9Jn}-OllamaModel-ThRiU{fieldName:input_value,id:OllamaModel-ThRiU,inputTypes:[Text],type:str}"},{"source":"OllamaModel-ThRiU","sourceHandle":"{baseClasses:[object,str,Text],dataType:OllamaModel,id:OllamaModel-ThRiU}","target":"ChatOutput-uZVOb","targetHandle":"{fieldName:input_value,id:ChatOutput-uZVOb,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-uZVOb","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OllamaModel","id":"OllamaModel-ThRiU"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OllamaModel-ThRiU{baseClasses:[object,str,Text],dataType:OllamaModel,id:OllamaModel-ThRiU}-ChatOutput-uZVOb{fieldName:input_value,id:ChatOutput-uZVOb,inputTypes:[Text],type:str}"},{"source":"ChatOutput-uZVOb","sourceHandle":"{baseClasses:[object,Record,str,Text],dataType:ChatOutput,id:ChatOutput-uZVOb}","target":"LanguageRecursiveTextSplitter-S1YTu","targetHandle":"{fieldName:inputs,id:LanguageRecursiveTextSplitter-S1YTu,inputTypes:[Document,Record],type:Record}","data":{"targetHandle":{"fieldName":"inputs","id":"LanguageRecursiveTextSplitter-S1YTu","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["object","Record","str","Text"],"dataType":"ChatOutput","id":"ChatOutput-uZVOb"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-ChatOutput-uZVOb{baseClasses:[object,Record,str,Text],dataType:ChatOutput,id:ChatOutput-uZVOb}-LanguageRecursiveTextSplitter-S1YTu{fieldName:inputs,id:LanguageRecursiveTextSplitter-S1YTu,inputTypes:[Document,Record],type:Record}"},{"source":"LanguageRecursiveTextSplitter-S1YTu","sourceHandle":"{baseClasses:[Record],dataType:LanguageRecursiveTextSplitter,id:LanguageRecursiveTextSplitter-S1YTu}","target":"MongoDBAtlasVector-QL9hJ","targetHandle":"{fieldName:inputs,id:MongoDBAtlasVector-QL9hJ,inputTypes:[Document,Record],type:Record}","data":{"targetHandle":{"fieldName":"inputs","id":"MongoDBAtlasVector-QL9hJ","inputTypes":["Document","Record"],"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"LanguageRecursiveTextSplitter","id":"LanguageRecursiveTextSplitter-S1YTu"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-LanguageRecursiveTextSplitter-S1YTu{baseClasses:[Record],dataType:LanguageRecursiveTextSplitter,id:LanguageRecursiveTextSplitter-S1YTu}-MongoDBAtlasVector-QL9hJ{fieldName:inputs,id:MongoDBAtlasVector-QL9hJ,inputTypes:[Document,Record],type:Record}"},{"source":"ChatOutput-uZVOb","sourceHandle":"{baseClasses:[object,Record,str,Text],dataType:ChatOutput,id:ChatOutput-uZVOb}","target":"MongoDBAtlasVectorSearch-PY4MJ","targetHandle":"{fieldName:input_value,id:MongoDBAtlasVectorSearch-PY4MJ,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"MongoDBAtlasVectorSearch-PY4MJ","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","Record","str","Text"],"dataType":"ChatOutput","id":"ChatOutput-uZVOb"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-ChatOutput-uZVOb{baseClasses:[object,Record,str,Text],dataType:ChatOutput,id:ChatOutput-uZVOb}-MongoDBAtlasVectorSearch-PY4MJ{fieldName:input_value,id:MongoDBAtlasVectorSearch-PY4MJ,inputTypes:[Text],type:str}"},{"source":"RunnableExecutor-RSDrm","sourceHandle":"{baseClasses:[object,str,Text],dataType:RunnableExecutor,id:RunnableExecutor-RSDrm}","target":"TextInput-axe6h","targetHandle":"{fieldName:input_value,id:TextInput-axe6h,inputTypes:[Record,Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"TextInput-axe6h","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"RunnableExecutor","id":"RunnableExecutor-RSDrm"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-RunnableExecutor-RSDrm{baseClasses:[object,str,Text],dataType:RunnableExecutor,id:RunnableExecutor-RSDrm}-TextInput-axe6h{fieldName:input_value,id:TextInput-axe6h,inputTypes:[Record,Text],type:str}"},{"source":"RunnableExecutor-RSDrm","sourceHandle":"{baseClasses:[object,str,Text],dataType:RunnableExecutor,id:RunnableExecutor-RSDrm}","target":"TextInput-9uD8V","targetHandle":"{fieldName:input_value,id:TextInput-9uD8V,inputTypes:[Record,Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"TextInput-9uD8V","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"RunnableExecutor","id":"RunnableExecutor-RSDrm"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-RunnableExecutor-RSDrm{baseClasses:[object,str,Text],dataType:RunnableExecutor,id:RunnableExecutor-RSDrm}-TextInput-9uD8V{fieldName:input_value,id:TextInput-9uD8V,inputTypes:[Record,Text],type:str}"},{"source":"ChatInput-ZBw8y","sourceHandle":"{baseClasses:[object,Record,str,Text],dataType:ChatInput,id:ChatInput-ZBw8y}","target":"RunnableExecutor-RSDrm","targetHandle":"{fieldName:input_value,id:RunnableExecutor-RSDrm,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"RunnableExecutor-RSDrm","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","Record","str","Text"],"dataType":"ChatInput","id":"ChatInput-ZBw8y"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-ChatInput-ZBw8y{baseClasses:[object,Record,str,Text],dataType:ChatInput,id:ChatInput-ZBw8y}-RunnableExecutor-RSDrm{fieldName:input_value,id:RunnableExecutor-RSDrm,inputTypes:[Text],type:str}"},{"source":"MongoDBAtlasVector-QL9hJ","sourceHandle":"{baseClasses:[MongoDBAtlasVectorSearch,VectorStore],dataType:MongoDBAtlasVector,id:MongoDBAtlasVector-QL9hJ}","target":"VectorStoreRetriever-qjsTT","targetHandle":"{fieldName:vectorstore,id:VectorStoreRetriever-qjsTT,inputTypes:null,type:VectorStore}","data":{"targetHandle":{"fieldName":"vectorstore","id":"VectorStoreRetriever-qjsTT","inputTypes":null,"type":"VectorStore"},"sourceHandle":{"baseClasses":["MongoDBAtlasVectorSearch","VectorStore"],"dataType":"MongoDBAtlasVector","id":"MongoDBAtlasVector-QL9hJ"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-MongoDBAtlasVector-QL9hJ{baseClasses:[MongoDBAtlasVectorSearch,VectorStore],dataType:MongoDBAtlasVector,id:MongoDBAtlasVector-QL9hJ}-VectorStoreRetriever-qjsTT{fieldName:vectorstore,id:VectorStoreRetriever-qjsTT,inputTypes:null,type:VectorStore}"},{"source":"VectorStoreRetriever-qjsTT","sourceHandle":"{baseClasses:[BaseRetriever,Generic,object,Runnable,RunnableSerializable,Serializable,VectorStoreRetriever],dataType:VectorStoreRetriever,id:VectorStoreRetriever-qjsTT}","target":"RunnableExecutor-fNcvp","targetHandle":"{fieldName:runnable,id:RunnableExecutor-fNcvp,inputTypes:[Chain,AgentExecutor,Agent,Runnable],type:Runnable}","data":{"targetHandle":{"fieldName":"runnable","id":"RunnableExecutor-fNcvp","inputTypes":["Chain","AgentExecutor","Agent","Runnable"],"type":"Runnable"},"sourceHandle":{"baseClasses":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStoreRetriever"],"dataType":"VectorStoreRetriever","id":"VectorStoreRetriever-qjsTT"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-VectorStoreRetriever-qjsTT{baseClasses:[BaseRetriever,Generic,object,Runnable,RunnableSerializable,Serializable,VectorStoreRetriever],dataType:VectorStoreRetriever,id:VectorStoreRetriever-qjsTT}-RunnableExecutor-fNcvp{fieldName:runnable,id:RunnableExecutor-fNcvp,inputTypes:[Chain,AgentExecutor,Agent,Runnable],type:Runnable}"},{"source":"LanguageRecursiveTextSplitter-xQXxD","sourceHandle":"{baseClasses:[Record],dataType:LanguageRecursiveTextSplitter,id:LanguageRecursiveTextSplitter-xQXxD}","target":"TextInput-zIhwT","targetHandle":"{fieldName:input_value,id:TextInput-zIhwT,inputTypes:[Record,Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"TextInput-zIhwT","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Record"],"dataType":"LanguageRecursiveTextSplitter","id":"LanguageRecursiveTextSplitter-xQXxD"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-LanguageRecursiveTextSplitter-xQXxD{baseClasses:[Record],dataType:LanguageRecursiveTextSplitter,id:LanguageRecursiveTextSplitter-xQXxD}-TextInput-zIhwT{fieldName:input_value,id:TextInput-zIhwT,inputTypes:[Record,Text],type:str}"},{"source":"TextInput-zIhwT","sourceHandle":"{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-zIhwT}","target":"RunnableExecutor-fNcvp","targetHandle":"{fieldName:input_value,id:RunnableExecutor-fNcvp,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"RunnableExecutor-fNcvp","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"TextInput","id":"TextInput-zIhwT"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-TextInput-zIhwT{baseClasses:[object,str,Text],dataType:TextInput,id:TextInput-zIhwT}-RunnableExecutor-fNcvp{fieldName:input_value,id:RunnableExecutor-fNcvp,inputTypes:[Text],type:str}"},{"source":"RunnableExecutor-fNcvp","sourceHandle":"{baseClasses:[object,str,Text],dataType:RunnableExecutor,id:RunnableExecutor-fNcvp}","target":"ChatOutput-uyk8S","targetHandle":"{fieldName:input_value,id:ChatOutput-uyk8S,inputTypes:[Text],type:str}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-uyk8S","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"RunnableExecutor","id":"RunnableExecutor-fNcvp"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-RunnableExecutor-fNcvp{baseClasses:[object,str,Text],dataType:RunnableExecutor,id:RunnableExecutor-fNcvp}-ChatOutput-uyk8S{fieldName:input_value,id:ChatOutput-uyk8S,inputTypes:[Text],type:str}"}],"viewport":{"x":-1719.1786018709445,"y":-148.98003495963758,"zoom":0.8752524124587516}},"description":"This allows us to analyse the data from the users that are a part of the MongoDB Vector Store\n","name":"DBMS Retail Data Analysis ","last_tested_version":"1.0.0a32","is_component":false}